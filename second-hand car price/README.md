
#零基础入门数据挖掘 -二手车交易价格预测

2020年天池与开源AI学习组织Datawhale合作举办的数据竞赛，详情见：https://tianchi.aliyun.com/competition/entrance/231784/information

主要分为赛题理解，数据探索，特征工程，建模调参与模型融合这五部分。

#1、赛题理解
主要是对赛题进行分析，对数据进行先验知识的理解。
我看竞赛5群有个队伍的赛题理解挖的蛮深的，贴一下他们的连接：https://shimo.im/docs/RhQKcjD8qtw9XQYt/read
关于数据理解方面，主要包括字段含义（明确特征处理，匿名特征处理等等）、数据量（电脑配置）、评测标准、结果提交（注意格式要求），我们也可以从已给的数据当中构造属性，eg：此次竞赛的用车时间大约等于广告发布时间-汽车注册时间，即usedatecreatdate-regdate。
在看完赛题与数据之后，我们根据自己已有的经验，在心里给自己一个baseline方案。随后，再在baseline方案的基础上去不断修改自己的版本（注意版本迭代的保存，方便自己返回之前的版本），直至采用的评价准则达到比较好的效果。

#2、数据探索
我把它分为如下几个小点：
(1)整体数据把握：包括读入数据之后，首先利用.shape查看数据维度，然后利用.head()与.tail()查看数据的前五行和最后五行了解其列数以及每列的具体value.
(2)数据统计信息：包括利用.info()查看列索引名称，每列有多少缺失值以及每列的数据类型（float,object等等);利用.describe()查看每列个数，平均值，最大值，最小值，3/4分位数，标准差等等值。
(3)异常值的处理：利用.isnull().sun()可查看数据每一列的缺失个数情况，我们也可以利用柱形图plot.bar()以及.matrix(data.sample(250/1k))等方法对缺失值进行可视化；对特殊的列进行处理，例如对于类型为object的列，我们可以利用.value.counts()查看此列的各值统计的种类与个数情况等等，对于不合理的value我们可以对其进行替换，eg:利用.replace('-',np.nan,inplace=True)将'-'替换为缺失值NAN等，再比如对于数据分布严重倾斜的列，其统计是无意义的，因此我们可以选择将其删除，eg，此次比赛的“seler”与“offertype”
(4)查看预测分布：对于我们整个模型需要预测的数据price，我们要通过训练数据的直接输出和.value_counts()对它有一个整体的把握。对其（1）总体分布概况，符合正态，对数正态还是无界约翰逊分布，（若进行回归分析，则需要保证分布符合正态，有时可通过对数据求对数log以满足前提假设）；（2)2) 查看偏度和峰度skewness and kurtosis；
(5）特征分类判别：对于特征，我们一般将其分为类别特征或者数字特征，可以通过dtype是number or object来简单地辨别，但真实场景中此种方法肯定是不行的。因为有时提供的数据早已对本来应该是类别的特征数字化，所以我们就需要通过已有的先验知识以及常识来对特征进行分类，分为numeric_features与categorical_features。并对于categorical_features特征通过.nunique()来查看其分布情况，包括种类与个数等等。
   5.1 数字特征分析
   对于数字特征，我们可以通过
   （1）相关性分析.corr()再构造热力图sns.heatmap()很明显地看出各个数字特征之间地相关性是高度相关还是基本不相关，且关注除price以外地特征对price的具体影响。
   （2）查看几个数字特征的偏度和峰值情况。
   （3）通过pd.melt()对每个数字特征本身的分布进行可视化sns.FacetGrid()再总体统计.map(sns.distplot()).
   （4）多变量互相回归关系可视化，可视化每一个特征对于输出price的影响，若某些分布图高度相似，说明这些特征高度相关，可能只要一个就可以表达出对price同样的效果。
   5.2 类别特征分析
   （1）unique分布，通过.unique()查看其是否是稀疏的，删除特别稀疏的特征，因为对于结果的预测没有实际的意义。
   （2）类别特征箱形图可视化，通过箱型图查看是否有异常值，也可以看出不同数据分布的对比。
   （3）类别特征的小提琴图可视化，箱型图进阶版，最大的不同是不仅可以看出是否有异常值，还能够看出在每个value上面的个数fenbuqk，数据集中或者稀疏分布在那个区域等等。
   （4）类别特征的柱形图可视化
(6)用pandas_profiling生成数据报告，这是pandas一个非常强大的功能，其不仅对数据总体进行了统计，还对每个变量的情况（是否稀疏，基数是否大等等）进行了统计，个人觉得几乎包含了前面所有的手动数据探索，而且warnings部分还能对你特征工程的构造有很多启发，例如删除太稀疏的特征，高相关的特征多取一等等情况，真是一大利器，疯狂打call。不过话说回来，生成这个html可视化版本在我的小笔记本上面花费了很多时间，奈何我不会用服务器~
   
   
